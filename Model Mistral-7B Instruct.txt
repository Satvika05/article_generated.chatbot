Model: Mistral-7B Instruct  
Developer: Mistral AI  
Source: https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1  
Model Size: 7 billion parameters  
Why Chosen: Mistral offers high-speed inference and top-tier performance in summarization and generation benchmarks.  
Strengths: High coherence, great for structured article output, better safety tuning than earlier LLMs.  
Usage: Used via Transformers pipeline with zero-shot or few-shot prompts.
