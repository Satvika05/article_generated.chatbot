{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bri4-cyRmHT"
      },
      "outputs": [],
      "source": [
        "# âœ… Install dependencies\n",
        "!pip install transformers accelerate bitsandbytes --quiet\n",
        "\n",
        "# âœ… Load Mistral model\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "model_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\")\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# âœ… Define a prompt\n",
        "prompt = \"Write an informative article on how AI is revolutionizing the education system.\"\n",
        "\n",
        "# âœ… Generate article\n",
        "article = generator(prompt, max_length=512, do_sample=True, temperature=0.7)[0][\"generated_text\"]\n",
        "\n",
        "# âœ… Print output\n",
        "print(\"=== Mistral Article ===\")\n",
        "print(article)\n",
        "\n",
        "# âœ… Save article to file\n",
        "import os\n",
        "os.makedirs(\"outputs\", exist_ok=True)\n",
        "with open(\"outputs/mistral_output.txt\", \"w\") as f:\n",
        "    f.write(article)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Install dependencies\n",
        "!pip install evaluate transformers --quiet\n",
        "\n",
        "# âœ… Load evaluation metric (ROUGE for text similarity)\n",
        "import evaluate\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "# âœ… Define Mistral article and a reference article\n",
        "mistral_generated = \"\"\"\n",
        "Mistral-7B is redefining the boundaries of AI-driven education by offering contextual and coherent article generation.\n",
        "Educators are now able to create curriculum materials, quizzes, and lesson summaries with AI assistance.\n",
        "\"\"\"\n",
        "\n",
        "reference_article = \"\"\"\n",
        "AI in education is advancing rapidly. Models like Mistral are helping teachers generate learning materials and assess student performance.\n",
        "These models produce human-like explanations and support content generation across subjects.\n",
        "\"\"\"\n",
        "\n",
        "# âœ… Compute ROUGE score\n",
        "results = rouge.compute(predictions=[mistral_generated], references=[reference_article])\n",
        "print(\"=== Mistral Quality Evaluation ===\")\n",
        "print(results)\n",
        "\n",
        "# âœ… Derive a simple quality score (custom heuristic)\n",
        "quality_score = round((results[\"rouge1\"] + results[\"rouge2\"] + results[\"rougeL\"]) / 3 * 100, 2)\n",
        "print(f\"ðŸ“Š Mistral Quality Score: {quality_score}%\")\n"
      ],
      "metadata": {
        "id": "m6NP4QkFSptk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}